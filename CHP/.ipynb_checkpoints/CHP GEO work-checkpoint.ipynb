{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits.mplot3d import axes3d\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "# load numerical analysis library.\n",
    "import numpy as np\n",
    "import scipy as scipy\n",
    "\n",
    "#matplotlib is the python library for making plots.  The below dictionary updates\n",
    "#change the default settings such as font size, tick size, etc.\n",
    "matplotlib.rcParams.update(\n",
    "    {'font.sans-serif': 'Arial',\n",
    "     'font.size': 10,\n",
    "     'font.family': 'Arial',\n",
    "     'mathtext.default': 'regular',\n",
    "     'axes.linewidth': 0.3, \n",
    "     'axes.labelsize': 10,\n",
    "     'xtick.labelsize': 10,\n",
    "     'ytick.labelsize': 10,     \n",
    "     'lines.linewidth': 0.5,\n",
    "     'legend.frameon': False,\n",
    "     'xtick.major.width': 0.3,\n",
    "     'xtick.minor.width': 0.3,\n",
    "     'ytick.major.width': 0.3,\n",
    "     'ytick.minor.width': 0.3,\n",
    "     'xtick.major.size': 3,\n",
    "     'ytick.major.size': 3,\n",
    "     'xtick.minor.size': 1,\n",
    "     'ytick.minor.size': 1\n",
    "    })\n",
    "\n",
    "# This tells matplotlib to create the plots in an \"inline\" format that the \n",
    "# web browser can display.\n",
    "%matplotlib inline\n",
    "\n",
    "# This adjusts the DPI (pixel resolution of the plots displayed).  Increase the DPI \n",
    "# for higher resolution images.\n",
    "import IPython\n",
    "IPython.display.set_matplotlib_formats('png', facecolor='#FFFFFF', dpi=1*108.8)\n",
    "\n",
    "# This sets the default size the plots generated by matplotlib.  It has to be called after the \n",
    "# previous lines that sets the default DPI.\n",
    "# This needs to occur after the IPython call.\n",
    "matplotlib.rcParams.update(\n",
    "    {'figure.figsize': (4,3)})\n",
    "\n",
    "# matplotlib objects used to position tick marks on plots.\n",
    "from matplotlib.ticker import MaxNLocator, LinearLocator, MultipleLocator\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "\n",
    "# These are neat objects that allow some primitive interaction such as that \n",
    "# used in the spectrum browswer.\n",
    "#from IPython.html.widgets import interact, interactive, fixed\n",
    "from IPython.html import widgets\n",
    "\n",
    "# This is a bit more of an advanced programming thing for my usage.  I basically \n",
    "# create objects for each data file and use them to keep track of the analysis \n",
    "# progression and steps.\n",
    "class Bunch(object):\n",
    "    def __init__(self, **kwds):\n",
    "        self.__dict__.update(kwds)\n",
    "        \n",
    "from scipy import stats\n",
    "#import prettyPy as pp\n",
    "\n",
    "import h5py\n",
    "import glob\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "#import plotly.plotly as py\n",
    "#from plotly.graph_objs import *\n",
    "import itertools\n",
    "from geopandas import GeoDataFrame\n",
    "pd.set_option('display.max_rows', 30000)\n",
    "import geopandas as gpd\n",
    "import geoplot as gplt\n",
    "import geoplot.crs as gcrs\n",
    "import matplotlib.pyplot as plt\n",
    "import mapclassify as mc\n",
    "from geopy.geocoders import Nominatim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dgarfiel/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "City_to_County = pd.read_csv(\"ua_county_rel_10.csv\" , sep='\\s*,\\s*')\n",
    "State_FIPS = pd.read_csv('State FIPS.csv', sep=',')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dgarfiel/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "CHP_to_City = pd.read_csv(\"CHPDB_database.csv\" , sep='\\s*,\\s*', error_bad_lines=False)\n",
    "CHP_to_City = CHP_to_City.dropna(how='any')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHP_to_City[\"CITY_STATE\"] = CHP_to_City[\"City\"].map(str) + ',' + CHP_to_City[\"State\"]\n",
    "#print(CHP_to_City['CITY_STATE'])\n",
    "Locations = []\n",
    "County = []\n",
    "#test = geolocator.geocode(CHP_to_City['CITY_STATE'].iloc[9])\n",
    "#test_coordinates = [test.latitude, test.longitude]\n",
    "#test_coordinates = \",\".join(map(str, test_coordinates))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the County Codes through API\n",
    "import requests\n",
    "request = requests.get('http://www.datasciencetoolkit.org/street2coordinates')\n",
    "Lets_see = []\n",
    "County_data = []\n",
    "for loc in CHP_to_City['CITY_STATE']:\n",
    "    l=[]\n",
    "    URL = \"http://www.datasciencetoolkit.org/street2coordinates/\"\n",
    "    l.append(URL)\n",
    "    l.append(loc)\n",
    "    get_address = \"\".join(l)\n",
    "    data = requests.get(url = get_address)\n",
    "    data = data.json()\n",
    "    #print(data[loc])\n",
    "    if data[loc]!=None:\n",
    "        #print('none')\n",
    "        FIPS = data[loc][\"fips_county\"]\n",
    "        County_data.append(FIPS)\n",
    "    else:\n",
    "        County_data.append('NaN')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74\n",
      "Index(['State', 'Organization Name', 'NAICS', 'Capacity (kW)', 'Prime Mover',\n",
      "       'Fuel Class - Primary Fuel', 'FIPS County'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "CHP_to_City['FIPS County'] = County_data #Add County data to main dataframe\n",
    "#print(CHP_to_City.columns)\n",
    "CHP_Colin = CHP_to_City.drop(['City', 'Facility Name', 'Application', 'SIC4', 'CITY_STATE'], axis=1) #drop unneeded dataframe columns\n",
    "FIPS_null = np.array(CHP_Colin['FIPS County'])\n",
    "count_null = np.count_nonzero(FIPS_null=='NaN')\n",
    "print(count_null)\n",
    "\n",
    "State_FIPS['FIPS'] = State_FIPS['FIPS'].apply('{:0>2}'.format) #make State FIPS 2 digit with leading zeros\n",
    "#print(State_FIPS)\n",
    "FIPS_dict = dict(zip(State_FIPS['State'], State_FIPS['FIPS'])) #make dictionary from State FIPS\n",
    "\n",
    "\n",
    "CHP_Colin = CHP_Colin.replace({'State': FIPS_dict}) #replace state postal code with FIPS code\n",
    "print(CHP_Colin.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['NAICS', '2012 Code'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "NAICS_conversion = pd.read_csv('2007_to_2012_NAICS.csv', sep=',')\n",
    "print(NAICS_conversion.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAICS_dict = dict(zip(NAICS_conversion['NAICS'], NAICS_conversion['2012 Code'])) #make dictionary of 2007 and 2012 NAICS\n",
    "CHP_Colin['NAICS_2012'] = CHP_Colin['NAICS'].map( NAICS_dict ) #replace 2007 NAICS with 2012 NAICS\n",
    "CHP_Colin['NAICS_2012'].fillna(CHP_Colin['NAICS'], inplace=True) #backfill missing 2012 codes with 2007 codes that were less than 6 digits and did not change\n",
    "del CHP_Colin['NAICS'] #delete 2007 codes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHP_Colin.to_csv('CHP with Counties.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
